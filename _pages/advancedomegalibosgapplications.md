---
ID: 1418
post_title: Advanced Omegalib/OSG Applications
author: davm
post_date: 2016-08-10 00:26:48
post_excerpt: ""
layout: page
permalink: >
  http://localhost/wordpress/tutorials/advancedomegalibosgapplications/
published: true
panels_data:
  - |
    a:3:{s:7:"widgets";a:9:{i:0;a:6:{s:5:"title";s:0:"";s:4:"text";s:61:"<h3 style="text-align: center;">Omegalib Tutorial Series</h3>";s:20:"text_selected_editor";s:4:"html";s:5:"autop";b:1;s:12:"_sow_form_id";s:13:"578723843cea2";s:11:"panels_info";a:7:{s:5:"class";s:31:"SiteOrigin_Widget_Editor_Widget";s:3:"raw";b:0;s:4:"grid";i:0;s:4:"cell";i:0;s:2:"id";i:0;s:9:"widget_id";s:36:"1ea35202-0ffb-4952-88db-1380842ca3f4";s:5:"style";a:2:{s:7:"padding";s:3:"0px";s:18:"background_display";s:4:"tile";}}}i:1;a:5:{s:8:"headline";a:6:{s:4:"text";s:0:"";s:3:"tag";s:2:"h3";s:4:"font";s:7:"default";s:5:"color";b:0;s:5:"align";s:4:"left";s:24:"so_field_container_state";s:4:"open";}s:12:"sub_headline";a:6:{s:4:"text";s:0:"";s:3:"tag";s:2:"h3";s:4:"font";s:7:"default";s:5:"color";b:0;s:5:"align";s:6:"center";s:24:"so_field_container_state";s:4:"open";}s:7:"divider";a:8:{s:5:"style";s:5:"solid";s:6:"weight";s:4:"thin";s:5:"color";b:0;s:11:"side_margin";s:4:"20px";s:16:"side_margin_unit";s:2:"px";s:10:"top_margin";s:4:"20px";s:15:"top_margin_unit";s:2:"px";s:24:"so_field_container_state";s:4:"open";}s:12:"_sow_form_id";s:13:"57871dc1b3fe7";s:11:"panels_info";a:7:{s:5:"class";s:33:"SiteOrigin_Widget_Headline_Widget";s:3:"raw";b:0;s:4:"grid";i:0;s:4:"cell";i:0;s:2:"id";i:1;s:9:"widget_id";s:36:"42c24578-cfd7-4dd5-8d52-e5b5178da0b8";s:5:"style";a:2:{s:7:"padding";s:3:"0px";s:18:"background_display";s:4:"tile";}}}i:2;a:6:{s:5:"title";s:0:"";s:4:"text";s:563:"<h4>Tutorials</h4>
    <ol>
     	<li style="text-align: left;"><a href="/wordpress/tutorials/load-box/">Load Geometry </a></li>
     	<li style="text-align: left;"><a href="/wordpress/tutorials/building-the-scenegraph/"><strong>Building The Scenegraph</strong></a></li>
     	<li style="text-align: left;"><a href="/wordpress/tutorials/defining-interactions/"><strong>Defining Interactions</strong></a></li>
            <li style="text-align: left;"><a href="/wordpress/tutorials/advancedomegalibosgapplications/"><strong>Advanced Omegalib/OSG Applications</strong></a></li>
    
    </ol>
    ";s:20:"text_selected_editor";s:4:"html";s:5:"autop";b:1;s:12:"_sow_form_id";s:13:"576b4c626e8f5";s:11:"panels_info";a:7:{s:5:"class";s:31:"SiteOrigin_Widget_Editor_Widget";s:3:"raw";b:0;s:4:"grid";i:1;s:4:"cell";i:0;s:2:"id";i:2;s:9:"widget_id";s:36:"4a98973e-09c0-48a2-923d-fcbc887ca755";s:5:"style";a:1:{s:18:"background_display";s:4:"tile";}}}i:3;a:4:{s:5:"title";s:0:"";s:4:"text";s:255:"In the following tutorials we will show you, how to create, import and display cool models and bring them to the Data Arena.
    
    Graphics programming experience is not a prerequisite, although it will help to have some understanding of the graphics pipeline.";s:6:"filter";b:0;s:11:"panels_info";a:7:{s:5:"class";s:14:"WP_Widget_Text";s:3:"raw";b:0;s:4:"grid";i:1;s:4:"cell";i:1;s:2:"id";i:3;s:9:"widget_id";s:36:"8458d952-2849-47ac-8244-b11bcc3949d1";s:5:"style";a:1:{s:18:"background_display";s:4:"tile";}}}i:4;a:6:{s:5:"title";s:0:"";s:4:"text";s:983:"<h4>Technology stack</h4><p>(maybe make a diagram of technology stack here?)</p><p>The Data Arena synchronizes its displays using a library called Equalizer to replicate low-level graphics commands over a network. However you will most probably not have to interact with it. The user builds graphical applications by using omegalib (insert link), cyclops and/or OpenSceneGraph. Omegalib is middleware designed to ease the development of applications for virtual reality (VR) and immersive display environments and can integrate a variety of other frameworks. We use OpenSceneGraph (insert link), a powerful graphics rendering library, to render our graphics.</p><p>However, OpenSceneGraph is also a fairly complex library with a steep learning curve. Therefore, cyclops (insert link), a high-level API for osg is used to do common graphic operations in the Data Arena. The Data Arena also provides custom classes to handle standard use-cases and to ease the first steps.</p><p> </p>";s:20:"text_selected_editor";s:4:"tmce";s:5:"autop";b:1;s:12:"_sow_form_id";s:13:"5771c634a985b";s:11:"panels_info";a:7:{s:5:"class";s:31:"SiteOrigin_Widget_Editor_Widget";s:3:"raw";b:0;s:4:"grid";i:2;s:4:"cell";i:1;s:2:"id";i:4;s:9:"widget_id";s:36:"1391920e-3d6d-43e3-a359-05f94389c1e0";s:5:"style";a:1:{s:18:"background_display";s:4:"tile";}}}i:5;a:13:{s:5:"image";i:392;s:14:"image_fallback";s:0:"";s:4:"size";s:4:"full";s:5:"align";s:7:"default";s:5:"title";s:0:"";s:14:"title_position";s:6:"hidden";s:3:"alt";s:0:"";s:3:"url";s:0:"";s:5:"bound";b:1;s:12:"_sow_form_id";s:13:"5771ca398cf62";s:10:"new_window";b:0;s:10:"full_width";b:0;s:11:"panels_info";a:7:{s:5:"class";s:30:"SiteOrigin_Widget_Image_Widget";s:3:"raw";b:0;s:4:"grid";i:2;s:4:"cell";i:2;s:2:"id";i:5;s:9:"widget_id";s:36:"9a9a63cf-976e-40c5-be98-63c4b0bc425e";s:5:"style";a:2:{s:7:"padding";s:4:"20px";s:18:"background_display";s:4:"tile";}}}i:6;a:4:{s:5:"title";s:0:"";s:4:"text";s:14752:"<pre><code>The *omega::Camera* also has a lookat method, however, if you update the *omega::Camera* by using its lookat method, it will produce weird, incorrect rotations, which are a symptom of the wrong coordinate frame of the center vector: The coordinate frame of the calculated center vector is in the camera view space but should really be in the world space.
    
    ```c++
    void NodeTrackerManipulator::updateOmegaCamera(omega::Camera *cam){
        osg::Vec3d eye, unused_center, up;
    
        // call same method, that osg internally uses for its camera updates
        osg::Matrixd invMatrix = getInverseMatrix();
        invMatrix.getLookAt(eye, unused_center, up);
    
        osg::NodePath nodePath;
        //get the path from the tracked node to the top level element
        getTrackNodePath().getNodePath(nodePath);
        //compute a transform from the tracked node space to world space
        osg::Matrixd localToWorld = osg::computeLocalToWorld(nodePath, true);
        // apply this transformation to the cameramanipulator center
        // this is normally the tracked node center, but might be panned
        osg::Vec3d worldCenter = _center * localToWorld;
    
        omega::Vector3f oCenterVec = OSGVEC3_OMEGA(worldCenter);
        // set the lookat of omega camera
        //order is important here, setting lookat before position 
        // will result in choppy camera rotation
        cam-&gt;setPosition( OSGVEC3_OMEGA(eye) );
        cam-&gt;lookAt(oCenterVec, OSGVEC3_OMEGA(up) );     
    }</code></pre>
    <h3>Executing pre-render cameras</h3>
    <p>In osg, cameras can have different render orders: Pre-render, normal, and post-render.<br />
    Pre-render cameras are often used, to render a certain effect into a texture, which are then used in the actual rendering of the scene. A common use case is rendering reflections on surfaces.</p>
    <p>In our game, we want to render a very shiny surface. A pre-render camera is used, to render the scene with a flipped z-transform:</p>
    <p>(todo: extract and insert snapshot from presentation)</p>
    <p>Our camera therefore moves with the main camera and its position has to be updated accordingly. Setting the transformation of the reflection camera at the right time is crucial, because setting it too late will result in the reflection lagging one frame behind and too early will result in the main camera not being updated with the new transform yet. A hacky method  could be to directly copy over the main camera transform to the reflection camera, when it is set in the cameramanipulator. However, this could break as soon as we have other methods influencing the camera position: imagine a method setting the field of view dynamically or a method preventing cameras flying into obstacles. Another problem is, that in omega multiple windows can be created on one machine, each update method is therefore executed once for each camera.If you have two windows, you will probably see constantly switching reflections between the windows, because the transform is applied to the wrong reflection camera. What we actually want is to have a camera callback executed right before the reflection camera is rendered. </p>
    <p>In osg, the cull traverse decides what objects to render and what to cull away. The Cullvisitor actually computes the correct transformation of each node and pushes objects into the the draw stage, which is executed after the Cullvisitor has visited all nodes. Therefore, the CullCallback is the latest point, we can influence a nodes transform before it is rendered. However the cullcallback is executed after the node transforms have already been pushed into the render stage.If we would therefore execute the cullcallback directly on the camera, we would not see any positional change. We must therefore set the cullcallback on a node above the camera (we named it cameragroup) and then access its child:</p>
    <p>&#8220;`c++<br />
    class CUpdateCameraCallback : public osg::NodeCallback<br />
    {<br />
    public:<br />
    CUpdateCameraCallback() : NodeCallback(){}<br />
    void operator()(osg::Node <em>node, osg::NodeVisitor </em>nv)<br />
    {<br />
    // only execute this callback if in the culling stage<br />
    if (nv-&gt;getVisitorType() == osg::NodeVisitor::CULL_VISITOR)<br />
    {<br />
    // the camera is the only child of the camera group<br />
    osg::Camera <em>camera = dynamic_cast&lt;osg::Camera </em>&gt;(node-&gt;asGroup()-&gt;getChild(0));<br />
    // The cullvisitor holds information about the current (main) camera<br />
    osgUtil::CullVisitor<em> cv = static_cast&lt;osgUtil::CullVisitor</em>&gt;(nv);</p>
    <pre><code>        if (camera != NULL)
            {
                // copy over the transforms of the main camera
                camera-&gt;setProjectionMatrix(cv-&gt;getCurrentCamera()-&gt;getProjectionMatrix() );
                camera-&gt;setViewMatrix(cv-&gt;getCurrentCamera()-&gt;getViewMatrix());
                // set the eye point in the shader
                g_cameraEyeU-&gt;set(cv-&gt;getEyePoint());
            }
        }
        this-&gt;traverse(node, nv);
    }</code></pre>
    <p>};</p>
    <pre><code>
    Now we show , how to set up the camera correctly:
    ```c++
        cameraGroup = new osg::Group();
        m_reflectionCamera = new osg::Camera();
        reflectionTransform = new osg::MatrixTransform();
    
        cameraGroup-&gt;addChild(m_reflectionCamera);
        m_reflectionCamera-&gt;addChild(reflectionTransform);
    
        m_reflectionCamera-&gt;setClearMask(GL_DEPTH_BUFFER_BIT | GL_COLOR_BUFFER_BIT);
        // render the camera before the main camera
        m_reflectionCamera-&gt;setRenderOrder(osg::Camera::PRE_RENDER);
        // write into a frame buffer later used as texture
        m_reflectionCamera-&gt;setRenderTargetImplementation(osg::Camera::FRAME_BUFFER_OBJECT);
        // prevent near clipping
        m_reflectionCamera-&gt;setComputeNearFarMode(osg::CullSettings::DO_NOT_COMPUTE_NEAR_FAR);
        // calculate all transforms in world space
        m_reflectionCamera-&gt;setReferenceFrame(osg::Transform::ABSOLUTE_RF);
        // set the viewport to the size of the texture
        m_reflectionCamera-&gt;setViewport(0, 0, texSize, texSize);
        m_reflectionCamera-&gt;setClearDepth(1.0);
    
        //Important: set our cull callback on the cameragroup, not the camera itself
        m_cameraGroupCallback = new CUpdateCameraCallback();
        cameraGroup-&gt;setCullCallback(m_cameraGroupCallback);</code></pre>
    <p>Calculating the actual reflection does not need any extra adjustements for distributed rendering, but is shown here for reference:<br />
    &#8220;`c++<br />
    // add a clipping plane, to clip everything below z=0.0.<br />
    //beware, that vec4(a,b,c,d) is a plane equation with a,b,c the plane normal and d the plane height<br />
    m_reflectionClipPlane = new osg::ClipPlane(0, osg::Vec4d(0.0, 0.0, 1.0, 0.0));<br />
    m_reflectionClipNode = new osg::ClipNode;<br />
    m_reflectionClipNode-&gt;addClipPlane(m_reflectionClipPlane);<br />
    reflectionTransform-&gt;addChild(m_reflectionClipNode);<br />
    // mirror the scene along the z axis<br />
    reflectionTransform-&gt;setMatrix(osg::Matrix::scale(1.0, 1.0, -1.0));</p>
    <pre><code>// render the reflection camera into a texture
    osg::ref_ptr&lt;osg::Texture2D&gt; texture = new osg::Texture2D();
    texture-&gt;setTextureSize(texSize, texSize);
    m_reflectionCamera-&gt;attach((osg::Camera::BufferComponent) osg::Camera::COLOR_BUFFER0, texture);
    
    osg::StateSet *cameraState = m_reflectionCamera-&gt;getOrCreateStateSet();
    cameraState-&gt;setMode(GL_CULL_FACE, osg::StateAttribute::OFF | osg::StateAttribute::OVERRIDE);
    // Set reflection textures
    osg::StateSet* floorStateSet = reflectingSurface-&gt;getOrCreateStateSet();
    floorStateSet-&gt;setTextureAttributeAndModes(0, texture, osg::StateAttribute::ON);</code></pre>
    <pre><code>The complete reflection code is found in source/view/reflection.cpp and shaders/grid.(vert|frag)
    
    ## Distributed rendering with omegalib+osg+equalizer
    
    When programming an application in omegalib, the underlying displaysystem (equalizer) is mostly opaque to the programmer. It is however important to understand what is going on, when programming for a distributed, parallel rendering environment such as the Data Arena. 
    
    ##### What is parallel rendering ?
    Quoting the introduction chapter of the Equalizer programming guide:
    
    (insert figure 1 of equalizer programming guide)
    
    Figure ? illustrates the basic principle of any parallel rendering application. The  typical OpenGL application, for example using GLUT, has an event loop which redraws the scene, updates application data based on received events, and eventually renders a new frame.
    A parallel rendering application uses the same basic execution model, extending it by separating the rendering code from the main event loop. The rendering code is then executed in parallel on different resources, depending on the configuration chosen at runtime.
    
    ##### How does parallel rendering work in omegalib ?
    
    (insert diagramOmegaFrame.png)
    
    Rendering a frame with omegalib 
    
    The EqualizerDisplaySystem in omegalib runs the mainloop and calls the Configimpl startFrame method. ConfigImpl is a implementation of the Config class methods in Equalizer. For an in-depth discussion of the various Equalizer concepts, check out the Equalizer Programming Guide, it is recommended to read the Introduction chapter and the "Equalizer Parallel Rendering Framework" chapter. 
    
    The master, which drives the slaves rendering, first shares all Events to all nodes, each node is then reponsible for handling these Events. When handling events, commonly things such as calculating the new camera position are performed. Then other shared data is synced, for example a user could sync the position of an object across the nodes. Next the update call is performed on the master, which calls the update method on all registered modules. The update method internally calculates the correct offset of each screen camera, therefore the camera position should not be changed after the update traversal anymore. The update callback is also the place for the user to do any larger computations, such as running a physics simulation step. The startFrame(version) method tells all slave nodes to update themselves. It carries the frame version to sync all nodes to render the same frame. After all updates have been performed all nodes render the frame, which translates to calls to the osgModule, which executes culling and drawing traversals. Finally all nodes are synced on the end of the frame again.
    
    Of course, this process has some intrecate issues that can arise when building complex applications. Often looking at the source code of omegalib, without having to extensively debug, can solve the issue as the code is fairly well commented.
    
    ## Data sharing and dynamic geometry
    
    Any moving objects, which are synchronized over multiple screens should use the shared data commit/update pattern.
    Equalizer handles distribution of datastreams to clients. Data can be added/extracted from the stream by calling
    ```c++
    // only run on master
    void commitSharedData(omega::SharedOStream&amp; out)
    {
        out &lt;&lt; myPosition;
    }
    // only run on slaves!
    void updateSharedData(omega::SharedIStream&amp; in)
    {
        in &gt;&gt; myPosition;
    }</code></pre>
    <p>on a omegamodule class. We implemented this for all the relevant game classes using a listener pattern:<br />
    An interface is declared as<br />
    &#8220;`c++<br />
    class SharedDataListener {<br />
    public:<br />
    virtual void commitSharedData(omega::SharedOStream&amp; out) = 0;<br />
    virtual void updateSharedData(omega::SharedIStream&amp; in) = 0;<br />
    };</p>
    <pre><code>and all classes which want to commit data to the stream inherit and implement this interface.
    Then register the listening classes in you omega module and iteratively dispatch them. Note that the input must the same order as the output.
    
    An example of synchronizing a dynamic gemeotry is the fence, which trails the bike in the Troen game.
    First we create a Geometry with a vertex array and quad strip primitive set:
    
    ```c++
    void FenceView::initializeFence()
    {
        m_coordinates = new osg::Vec3Array();
        m_coordinates-&gt;setDataVariance(osg::Object::DYNAMIC);
    
        m_geometry = new osg::Geometry();
        m_geometry-&gt;setVertexArray(m_coordinates);
    
        // use VBOs, not display lists. important for dynamic updates
        m_geometry-&gt;setUseDisplayList(false);
    
        m_drawArrays = new osg::DrawArrays(osg::PrimitiveSet::QUAD_STRIP, 0, 0);
        m_geometry-&gt;addPrimitiveSet(m_drawArrays);
    }</code></pre>
    <p>In our update method, we add a new fence part, when the bike has moved a certain distance. When porting osg applications to omegalib, always make sure that all modified vertex arrays and geometry is dirtied, as else there will be crashes even if it runs fine under pure osg.<br />
    &#8220;`c++<br />
    void FenceView::addFencePart(osg::Vec3 currentPosition)<br />
    // game fence part<br />
    m_coordinates-&gt;push_back(currentPosition);<br />
    m_coordinates-&gt;push_back(currentPosition + osg::Vec3(0,0,10));<br />
    // trigger new boundary calculation<br />
    m_geometry-&gt;dirtyBound();<br />
    // very important to dirty vertex and attributes, as otherwise this will segfault in omegalib<br />
    m_coordinates-&gt;dirty();<br />
    // update the size of the draw array<br />
    m_drawArrays-&gt;setCount(m_coordinates-&gt;size());<br />
    // if its the master, cache the position to use in the commit data method<br />
    if (omega::SystemManager::instance()-&gt;isMaster())<br />
    {<br />
    m_currentPositionCached = currentPosition;<br />
    m_fenceUpdated = true;<br />
    }</p>
    <pre><code>
    We call the *addFencePart* method in our update method, but only on the master. On the client, the method is called, when it receives new shared data:
    ```c++
    void FenceView::commitSharedData(omega::SharedOStream&amp; out)
    {
        out &lt;&lt; m_fenceUpdated &lt;&lt; m_currentPositionCached;
        // clear per frame states
        m_fenceUpdated = false;
    }
    
    void FenceView::updateSharedData(omega::SharedIStream&amp; in)
    {
        in &gt;&gt; m_fenceUpdated &gt;&gt;  m_currentPositionCached;
        if (m_fenceUpdated)
            addFencePart(m_currentPositionCached);
    }</code></pre>
    <p>It is usually not necessary to sync the physics state, because the commit/update method is called every frame and the datalink in the Data Arena has a low latency. In Troen, we only synchronize the view transforms and do not execute the physics simulation on the child nodes at all. By doing this, we ensure that all nodes are in a consistent state and we do not have to worry about diverging physics states.</p>
    <p>There can be situations however, where syncing the individual object transforms is not possible in a scalable manner, for example if a large particle system should be synced. In this case, the parameters of the particle system have to be synced and the simulation simultaneausly ran, setting random seeds uniformly.</p>
    			</div>";s:11:"panels_info";a:6:{s:5:"class";s:14:"WP_Widget_Text";s:4:"grid";i:3;s:4:"cell";i:1;s:2:"id";i:6;s:9:"widget_id";s:36:"8458d952-2849-47ac-8244-b11bcc3949d1";s:5:"style";a:2:{s:27:"background_image_attachment";b:0;s:18:"background_display";s:4:"tile";}}s:6:"filter";b:0;}i:7;a:6:{s:5:"title";s:0:"";s:4:"text";s:14705:"<pre><code>The *omega::Camera* also has a lookat method, however, if you update the *omega::Camera* by using its lookat method, it will produce weird, incorrect rotations, which are a symptom of the wrong coordinate frame of the center vector: The coordinate frame of the calculated center vector is in the camera view space but should really be in the world space.
    
    ```c++
    void NodeTrackerManipulator::updateOmegaCamera(omega::Camera *cam){
        osg::Vec3d eye, unused_center, up;
    
        // call same method, that osg internally uses for its camera updates
        osg::Matrixd invMatrix = getInverseMatrix();
        invMatrix.getLookAt(eye, unused_center, up);
    
        osg::NodePath nodePath;
        //get the path from the tracked node to the top level element
        getTrackNodePath().getNodePath(nodePath);
        //compute a transform from the tracked node space to world space
        osg::Matrixd localToWorld = osg::computeLocalToWorld(nodePath, true);
        // apply this transformation to the cameramanipulator center
        // this is normally the tracked node center, but might be panned
        osg::Vec3d worldCenter = _center * localToWorld;
    
        omega::Vector3f oCenterVec = OSGVEC3_OMEGA(worldCenter);
        // set the lookat of omega camera
        //order is important here, setting lookat before position 
        // will result in choppy camera rotation
        cam-&gt;setPosition( OSGVEC3_OMEGA(eye) );
        cam-&gt;lookAt(oCenterVec, OSGVEC3_OMEGA(up) );     
    }</code></pre><h3>Executing pre-render cameras</h3><p>In osg, cameras can have different render orders: Pre-render, normal, and post-render.<br /> Pre-render cameras are often used, to render a certain effect into a texture, which are then used in the actual rendering of the scene. A common use case is rendering reflections on surfaces.</p><p>In our game, we want to render a very shiny surface. A pre-render camera is used, to render the scene with a flipped z-transform:</p><p>(todo: extract and insert snapshot from presentation)</p><p>Our camera therefore moves with the main camera and its position has to be updated accordingly. Setting the transformation of the reflection camera at the right time is crucial, because setting it too late will result in the reflection lagging one frame behind and too early will result in the main camera not being updated with the new transform yet. A hacky method could be to directly copy over the main camera transform to the reflection camera, when it is set in the cameramanipulator. However, this could break as soon as we have other methods influencing the camera position: imagine a method setting the field of view dynamically or a method preventing cameras flying into obstacles. Another problem is, that in omega multiple windows can be created on one machine, each update method is therefore executed once for each camera.If you have two windows, you will probably see constantly switching reflections between the windows, because the transform is applied to the wrong reflection camera. What we actually want is to have a camera callback executed right before the reflection camera is rendered.</p><p>In osg, the cull traverse decides what objects to render and what to cull away. The Cullvisitor actually computes the correct transformation of each node and pushes objects into the the draw stage, which is executed after the Cullvisitor has visited all nodes. Therefore, the CullCallback is the latest point, we can influence a nodes transform before it is rendered. However the cullcallback is executed after the node transforms have already been pushed into the render stage.If we would therefore execute the cullcallback directly on the camera, we would not see any positional change. We must therefore set the cullcallback on a node above the camera (we named it cameragroup) and then access its child:</p><p>“`c++<br /> class CUpdateCameraCallback : public osg::NodeCallback<br /> {<br /> public:<br /> CUpdateCameraCallback() : NodeCallback(){}<br /> void operator()(osg::Node <em>node, osg::NodeVisitor </em>nv)<br /> {<br /> // only execute this callback if in the culling stage<br /> if (nv-&gt;getVisitorType() == osg::NodeVisitor::CULL_VISITOR)<br /> {<br /> // the camera is the only child of the camera group<br /> osg::Camera <em>camera = dynamic_cast&lt;osg::Camera </em>&gt;(node-&gt;asGroup()-&gt;getChild(0));<br /> // The cullvisitor holds information about the current (main) camera<br /> osgUtil::CullVisitor<em> cv = static_cast&lt;osgUtil::CullVisitor</em>&gt;(nv);</p><pre><code>        if (camera != NULL)
            {
                // copy over the transforms of the main camera
                camera-&gt;setProjectionMatrix(cv-&gt;getCurrentCamera()-&gt;getProjectionMatrix() );
                camera-&gt;setViewMatrix(cv-&gt;getCurrentCamera()-&gt;getViewMatrix());
                // set the eye point in the shader
                g_cameraEyeU-&gt;set(cv-&gt;getEyePoint());
            }
        }
        this-&gt;traverse(node, nv);
    }</code></pre><p>};</p><pre><code>
    Now we show , how to set up the camera correctly:
    ```c++
        cameraGroup = new osg::Group();
        m_reflectionCamera = new osg::Camera();
        reflectionTransform = new osg::MatrixTransform();
    
        cameraGroup-&gt;addChild(m_reflectionCamera);
        m_reflectionCamera-&gt;addChild(reflectionTransform);
    
        m_reflectionCamera-&gt;setClearMask(GL_DEPTH_BUFFER_BIT | GL_COLOR_BUFFER_BIT);
        // render the camera before the main camera
        m_reflectionCamera-&gt;setRenderOrder(osg::Camera::PRE_RENDER);
        // write into a frame buffer later used as texture
        m_reflectionCamera-&gt;setRenderTargetImplementation(osg::Camera::FRAME_BUFFER_OBJECT);
        // prevent near clipping
        m_reflectionCamera-&gt;setComputeNearFarMode(osg::CullSettings::DO_NOT_COMPUTE_NEAR_FAR);
        // calculate all transforms in world space
        m_reflectionCamera-&gt;setReferenceFrame(osg::Transform::ABSOLUTE_RF);
        // set the viewport to the size of the texture
        m_reflectionCamera-&gt;setViewport(0, 0, texSize, texSize);
        m_reflectionCamera-&gt;setClearDepth(1.0);
    
        //Important: set our cull callback on the cameragroup, not the camera itself
        m_cameraGroupCallback = new CUpdateCameraCallback();
        cameraGroup-&gt;setCullCallback(m_cameraGroupCallback);</code></pre><p>Calculating the actual reflection does not need any extra adjustements for distributed rendering, but is shown here for reference:<br /> “`c++<br /> // add a clipping plane, to clip everything below z=0.0.<br /> //beware, that vec4(a,b,c,d) is a plane equation with a,b,c the plane normal and d the plane height<br /> m_reflectionClipPlane = new osg::ClipPlane(0, osg::Vec4d(0.0, 0.0, 1.0, 0.0));<br /> m_reflectionClipNode = new osg::ClipNode;<br /> m_reflectionClipNode-&gt;addClipPlane(m_reflectionClipPlane);<br /> reflectionTransform-&gt;addChild(m_reflectionClipNode);<br /> // mirror the scene along the z axis<br /> reflectionTransform-&gt;setMatrix(osg::Matrix::scale(1.0, 1.0, -1.0));</p><pre><code>// render the reflection camera into a texture
    osg::ref_ptr&lt;osg::Texture2D&gt; texture = new osg::Texture2D();
    texture-&gt;setTextureSize(texSize, texSize);
    m_reflectionCamera-&gt;attach((osg::Camera::BufferComponent) osg::Camera::COLOR_BUFFER0, texture);
    
    osg::StateSet *cameraState = m_reflectionCamera-&gt;getOrCreateStateSet();
    cameraState-&gt;setMode(GL_CULL_FACE, osg::StateAttribute::OFF | osg::StateAttribute::OVERRIDE);
    // Set reflection textures
    osg::StateSet* floorStateSet = reflectingSurface-&gt;getOrCreateStateSet();
    floorStateSet-&gt;setTextureAttributeAndModes(0, texture, osg::StateAttribute::ON);</code></pre><pre><code>The complete reflection code is found in source/view/reflection.cpp and shaders/grid.(vert|frag)
    
    ## Distributed rendering with omegalib+osg+equalizer
    
    When programming an application in omegalib, the underlying displaysystem (equalizer) is mostly opaque to the programmer. It is however important to understand what is going on, when programming for a distributed, parallel rendering environment such as the Data Arena. 
    
    ##### What is parallel rendering ?
    Quoting the introduction chapter of the Equalizer programming guide:
    
    (insert figure 1 of equalizer programming guide)
    
    Figure ? illustrates the basic principle of any parallel rendering application. The  typical OpenGL application, for example using GLUT, has an event loop which redraws the scene, updates application data based on received events, and eventually renders a new frame.
    A parallel rendering application uses the same basic execution model, extending it by separating the rendering code from the main event loop. The rendering code is then executed in parallel on different resources, depending on the configuration chosen at runtime.
    
    ##### How does parallel rendering work in omegalib ?
    
    (insert diagramOmegaFrame.png)
    
    Rendering a frame with omegalib 
    
    The EqualizerDisplaySystem in omegalib runs the mainloop and calls the Configimpl startFrame method. ConfigImpl is a implementation of the Config class methods in Equalizer. For an in-depth discussion of the various Equalizer concepts, check out the Equalizer Programming Guide, it is recommended to read the Introduction chapter and the "Equalizer Parallel Rendering Framework" chapter. 
    
    The master, which drives the slaves rendering, first shares all Events to all nodes, each node is then reponsible for handling these Events. When handling events, commonly things such as calculating the new camera position are performed. Then other shared data is synced, for example a user could sync the position of an object across the nodes. Next the update call is performed on the master, which calls the update method on all registered modules. The update method internally calculates the correct offset of each screen camera, therefore the camera position should not be changed after the update traversal anymore. The update callback is also the place for the user to do any larger computations, such as running a physics simulation step. The startFrame(version) method tells all slave nodes to update themselves. It carries the frame version to sync all nodes to render the same frame. After all updates have been performed all nodes render the frame, which translates to calls to the osgModule, which executes culling and drawing traversals. Finally all nodes are synced on the end of the frame again.
    
    Of course, this process has some intrecate issues that can arise when building complex applications. Often looking at the source code of omegalib, without having to extensively debug, can solve the issue as the code is fairly well commented.
    
    ## Data sharing and dynamic geometry
    
    Any moving objects, which are synchronized over multiple screens should use the shared data commit/update pattern.
    Equalizer handles distribution of datastreams to clients. Data can be added/extracted from the stream by calling
    ```c++
    // only run on master
    void commitSharedData(omega::SharedOStream&amp; out)
    {
        out &lt;&lt; myPosition;
    }
    // only run on slaves!
    void updateSharedData(omega::SharedIStream&amp; in)
    {
        in &gt;&gt; myPosition;
    }</code></pre><p>on a omegamodule class. We implemented this for all the relevant game classes using a listener pattern:<br /> An interface is declared as<br /> “`c++<br /> class SharedDataListener {<br /> public:<br /> virtual void commitSharedData(omega::SharedOStream&amp; out) = 0;<br /> virtual void updateSharedData(omega::SharedIStream&amp; in) = 0;<br /> };</p><pre><code>and all classes which want to commit data to the stream inherit and implement this interface.
    Then register the listening classes in you omega module and iteratively dispatch them. Note that the input must the same order as the output.
    
    An example of synchronizing a dynamic gemeotry is the fence, which trails the bike in the Troen game.
    First we create a Geometry with a vertex array and quad strip primitive set:
    
    ```c++
    void FenceView::initializeFence()
    {
        m_coordinates = new osg::Vec3Array();
        m_coordinates-&gt;setDataVariance(osg::Object::DYNAMIC);
    
        m_geometry = new osg::Geometry();
        m_geometry-&gt;setVertexArray(m_coordinates);
    
        // use VBOs, not display lists. important for dynamic updates
        m_geometry-&gt;setUseDisplayList(false);
    
        m_drawArrays = new osg::DrawArrays(osg::PrimitiveSet::QUAD_STRIP, 0, 0);
        m_geometry-&gt;addPrimitiveSet(m_drawArrays);
    }</code></pre><p>In our update method, we add a new fence part, when the bike has moved a certain distance. When porting osg applications to omegalib, always make sure that all modified vertex arrays and geometry is dirtied, as else there will be crashes even if it runs fine under pure osg.<br /> “`c++<br /> void FenceView::addFencePart(osg::Vec3 currentPosition)<br /> // game fence part<br /> m_coordinates-&gt;push_back(currentPosition);<br /> m_coordinates-&gt;push_back(currentPosition + osg::Vec3(0,0,10));<br /> // trigger new boundary calculation<br /> m_geometry-&gt;dirtyBound();<br /> // very important to dirty vertex and attributes, as otherwise this will segfault in omegalib<br /> m_coordinates-&gt;dirty();<br /> // update the size of the draw array<br /> m_drawArrays-&gt;setCount(m_coordinates-&gt;size());<br /> // if its the master, cache the position to use in the commit data method<br /> if (omega::SystemManager::instance()-&gt;isMaster())<br /> {<br /> m_currentPositionCached = currentPosition;<br /> m_fenceUpdated = true;<br /> }</p><pre><code>
    We call the *addFencePart* method in our update method, but only on the master. On the client, the method is called, when it receives new shared data:
    ```c++
    void FenceView::commitSharedData(omega::SharedOStream&amp; out)
    {
        out &lt;&lt; m_fenceUpdated &lt;&lt; m_currentPositionCached;
        // clear per frame states
        m_fenceUpdated = false;
    }
    
    void FenceView::updateSharedData(omega::SharedIStream&amp; in)
    {
        in &gt;&gt; m_fenceUpdated &gt;&gt;  m_currentPositionCached;
        if (m_fenceUpdated)
            addFencePart(m_currentPositionCached);
    }</code></pre><p>It is usually not necessary to sync the physics state, because the commit/update method is called every frame and the datalink in the Data Arena has a low latency. In Troen, we only synchronize the view transforms and do not execute the physics simulation on the child nodes at all. By doing this, we ensure that all nodes are in a consistent state and we do not have to worry about diverging physics states.</p><p>There can be situations however, where syncing the individual object transforms is not possible in a scalable manner, for example if a large particle system should be synced. In this case, the parameters of the particle system have to be synced and the simulation simultaneausly ran, setting random seeds uniformly.</p>";s:20:"text_selected_editor";s:4:"tmce";s:5:"autop";b:1;s:12:"_sow_form_id";s:13:"5770c532d1e3d";s:11:"panels_info";a:6:{s:5:"class";s:31:"SiteOrigin_Widget_Editor_Widget";s:4:"grid";i:3;s:4:"cell";i:1;s:2:"id";i:7;s:9:"widget_id";s:36:"1391920e-3d6d-43e3-a359-05f94389c1e0";s:5:"style";a:2:{s:27:"background_image_attachment";b:0;s:18:"background_display";s:4:"tile";}}}i:8;a:14:{s:8:"features";a:3:{i:0;a:9:{s:15:"container_color";b:0;s:4:"icon";s:31:"fontawesome-arrow-circle-o-left";s:10:"icon_color";s:7:"#3d3d3d";s:10:"icon_image";i:0;s:15:"icon_image_size";s:4:"full";s:5:"title";s:0:"";s:4:"text";s:0:"";s:9:"more_text";s:17:"Previous Tutorial";s:8:"more_url";s:30:"/wordpress/tutorials/load-box/";}i:1;a:9:{s:15:"container_color";s:7:"#404040";s:4:"icon";s:0:"";s:10:"icon_color";s:7:"#FFFFFF";s:10:"icon_image";i:0;s:15:"icon_image_size";s:4:"full";s:5:"title";s:0:"";s:4:"text";s:0:"";s:9:"more_text";s:0:"";s:8:"more_url";s:0:"";}i:2;a:9:{s:15:"container_color";s:7:"#e8e8e8";s:4:"icon";s:32:"fontawesome-arrow-circle-o-right";s:10:"icon_color";s:7:"#3d3d3d";s:10:"icon_image";i:0;s:15:"icon_image_size";s:4:"full";s:5:"title";s:0:"";s:4:"text";s:0:"";s:9:"more_text";s:13:"Next Tutorial";s:8:"more_url";s:45:"/wordpress/tutorials/building-the-scenegraph/";}}s:5:"fonts";a:4:{s:13:"title_options";a:5:{s:4:"font";s:7:"default";s:4:"size";b:0;s:9:"size_unit";s:2:"px";s:5:"color";b:0;s:24:"so_field_container_state";s:6:"closed";}s:12:"text_options";a:5:{s:4:"font";s:7:"default";s:4:"size";b:0;s:9:"size_unit";s:2:"px";s:5:"color";b:0;s:24:"so_field_container_state";s:6:"closed";}s:17:"more_text_options";a:5:{s:4:"font";s:7:"default";s:4:"size";b:0;s:9:"size_unit";s:2:"px";s:5:"color";b:0;s:24:"so_field_container_state";s:6:"closed";}s:24:"so_field_container_state";s:6:"closed";}s:15:"container_shape";s:0:"";s:14:"container_size";s:4:"84px";s:19:"container_size_unit";s:2:"px";s:9:"icon_size";s:4:"24px";s:14:"icon_size_unit";s:2:"px";s:7:"per_row";i:3;s:10:"responsive";b:1;s:12:"_sow_form_id";s:13:"57873dc4344d9";s:10:"title_link";b:0;s:9:"icon_link";b:0;s:10:"new_window";b:0;s:11:"panels_info";a:7:{s:5:"class";s:33:"SiteOrigin_Widget_Features_Widget";s:3:"raw";b:0;s:4:"grid";i:5;s:4:"cell";i:0;s:2:"id";i:8;s:9:"widget_id";s:36:"9cfce0d0-9f38-47ab-930d-0f36248ba8e9";s:5:"style";a:1:{s:18:"background_display";s:4:"tile";}}}}s:5:"grids";a:6:{i:0;a:2:{s:5:"cells";i:1;s:5:"style";a:3:{s:7:"padding";s:3:"0px";s:5:"align";s:0:"";s:14:"column_padding";s:0:"";}}i:1;a:2:{s:5:"cells";i:3;s:5:"style";a:4:{s:7:"padding";s:4:"10px";s:5:"align";s:0:"";s:11:"row_stretch";s:4:"full";s:14:"column_padding";s:0:"";}}i:2;a:2:{s:5:"cells";i:4;s:5:"style";a:4:{s:7:"padding";s:3:"0px";s:5:"align";s:0:"";s:11:"row_stretch";s:4:"full";s:14:"column_padding";s:0:"";}}i:3;a:2:{s:5:"cells";i:3;s:5:"style";a:4:{s:7:"padding";s:4:"20px";s:5:"align";s:0:"";s:11:"row_stretch";s:4:"full";s:14:"column_padding";s:0:"";}}i:4;a:2:{s:5:"cells";i:3;s:5:"style";a:4:{s:7:"padding";s:4:"20px";s:5:"align";s:0:"";s:11:"row_stretch";s:4:"full";s:14:"column_padding";s:0:"";}}i:5;a:2:{s:5:"cells";i:1;s:5:"style";a:0:{}}}s:10:"grid_cells";a:15:{i:0;a:2:{s:4:"grid";i:0;s:6:"weight";i:1;}i:1;a:2:{s:4:"grid";i:1;s:6:"weight";d:0.227000000000000035083047578154946677386760711669921875;}i:2;a:2:{s:4:"grid";i:1;s:6:"weight";d:0.6910000000000000586197757002082653343677520751953125;}i:3;a:2:{s:4:"grid";i:1;s:6:"weight";d:0.082000000000000017319479184152442030608654022216796875;}i:4;a:2:{s:4:"grid";i:2;s:6:"weight";d:0.2295751633986897466410681545312399975955486297607421875;}i:5;a:2:{s:4:"grid";i:2;s:6:"weight";d:0.270424836601309726002995148519403301179409027099609375;}i:6;a:2:{s:4:"grid";i:2;s:6:"weight";d:0.41907785081558956985503527903347276151180267333984375;}i:7;a:2:{s:4:"grid";i:2;s:6:"weight";d:0.08092214918441091586753799447251367382705211639404296875;}i:8;a:2:{s:4:"grid";i:3;s:6:"weight";d:0.2312091503267995340475948751191026531159877777099609375;}i:9;a:2:{s:4:"grid";i:3;s:6:"weight";d:0.6937117253778286585230716809746809303760528564453125;}i:10;a:2:{s:4:"grid";i:3;s:6:"weight";d:0.07507912429537184906269686734958668239414691925048828125;}i:11;a:2:{s:4:"grid";i:4;s:6:"weight";d:0.229575163398691384220029476637137122452259063720703125;}i:12;a:2:{s:4:"grid";i:4;s:6:"weight";d:0.69444444444444408670591428744955919682979583740234375;}i:13;a:2:{s:4:"grid";i:4;s:6:"weight";d:0.07598039215686445968511719684101990424096584320068359375;}i:14;a:2:{s:4:"grid";i:5;s:6:"weight";i:1;}}}
---
<h3 style="text-align: center;">Omegalib Tutorial Series</h3>
<h4>Tutorials</h4>
<ol>
<li style="text-align: left;"><a href="/wordpress/tutorials/load-box/">Load Geometry </a></li>
<li style="text-align: left;"><a href="/wordpress/tutorials/building-the-scenegraph/"><strong>Building The Scenegraph</strong></a></li>
<li style="text-align: left;"><a href="/wordpress/tutorials/defining-interactions/"><strong>Defining Interactions</strong></a></li>
<li style="text-align: left;"><a href="/wordpress/tutorials/advancedomegalibosgapplications/"><strong>Advanced Omegalib/OSG Applications</strong></a></li>
</ol>
In the following tutorials we will show you, how to create, import and display cool models and bring them to the Data Arena.
Graphics programming experience is not a prerequisite, although it will help to have some understanding of the graphics pipeline.
&nbsp;&nbsp;
<h4>Technology stack</h4>
<p>(maybe make a diagram of technology stack here?)</p>
<p>The Data Arena synchronizes its displays using a library called Equalizer to replicate low-level graphics commands over a network. However you will most probably not have to interact with it. The user builds graphical applications by using omegalib (insert link), cyclops and/or OpenSceneGraph. Omegalib is middleware designed to ease the development of applications for virtual reality (VR) and immersive display environments and can integrate a variety of other frameworks. We use OpenSceneGraph (insert link), a powerful graphics rendering library, to render our graphics.</p>
<p>However, OpenSceneGraph is also a fairly complex library with a steep learning curve. Therefore, cyclops (insert link), a high-level API for osg is used to do common graphic operations in the Data Arena. The Data Arena also provides custom classes to handle standard use-cases and to ease the first steps.</p>
<p>&nbsp;</p>
<img src="http://localhost/wordpress/wp-content/uploads/2016/06/placeholder.jpg" width="498" height="367" srcset="http://localhost/wordpress/wp-content/uploads/2016/06/placeholder.jpg 498w, http://localhost/wordpress/wp-content/uploads/2016/06/placeholder-300x221.jpg 300w, http://localhost/wordpress/wp-content/uploads/2016/06/placeholder-230x169.jpg 230w, http://localhost/wordpress/wp-content/uploads/2016/06/placeholder-350x258.jpg 350w, http://localhost/wordpress/wp-content/uploads/2016/06/placeholder-480x354.jpg 480w" class="so-widget-image">
&nbsp;&nbsp;			<pre><code>The *omega::Camera* also has a lookat method, however, if you update the *omega::Camera* by using its lookat method, it will produce weird, incorrect rotations, which are a symptom of the wrong coordinate frame of the center vector: The coordinate frame of the calculated center vector is in the camera view space but should really be in the world space.
```c++
void NodeTrackerManipulator::updateOmegaCamera(omega::Camera *cam){
osg::Vec3d eye, unused_center, up;
// call same method, that osg internally uses for its camera updates
osg::Matrixd invMatrix = getInverseMatrix();
invMatrix.getLookAt(eye, unused_center, up);
osg::NodePath nodePath;
//get the path from the tracked node to the top level element
getTrackNodePath().getNodePath(nodePath);
//compute a transform from the tracked node space to world space
osg::Matrixd localToWorld = osg::computeLocalToWorld(nodePath, true);
// apply this transformation to the cameramanipulator center
// this is normally the tracked node center, but might be panned
osg::Vec3d worldCenter = _center * localToWorld;
omega::Vector3f oCenterVec = OSGVEC3_OMEGA(worldCenter);
// set the lookat of omega camera
//order is important here, setting lookat before position 
// will result in choppy camera rotation
cam-&gt;setPosition( OSGVEC3_OMEGA(eye) );
cam-&gt;lookAt(oCenterVec, OSGVEC3_OMEGA(up) );     
}</code></pre>
<h3>Executing pre-render cameras</h3>
<p>In osg, cameras can have different render orders: Pre-render, normal, and post-render.<br>
Pre-render cameras are often used, to render a certain effect into a texture, which are then used in the actual rendering of the scene. A common use case is rendering reflections on surfaces.</p>
<p>In our game, we want to render a very shiny surface. A pre-render camera is used, to render the scene with a flipped z-transform:</p>
<p>(todo: extract and insert snapshot from presentation)</p>
<p>Our camera therefore moves with the main camera and its position has to be updated accordingly. Setting the transformation of the reflection camera at the right time is crucial, because setting it too late will result in the reflection lagging one frame behind and too early will result in the main camera not being updated with the new transform yet. A hacky method  could be to directly copy over the main camera transform to the reflection camera, when it is set in the cameramanipulator. However, this could break as soon as we have other methods influencing the camera position: imagine a method setting the field of view dynamically or a method preventing cameras flying into obstacles. Another problem is, that in omega multiple windows can be created on one machine, each update method is therefore executed once for each camera.If you have two windows, you will probably see constantly switching reflections between the windows, because the transform is applied to the wrong reflection camera. What we actually want is to have a camera callback executed right before the reflection camera is rendered. </p>
<p>In osg, the cull traverse decides what objects to render and what to cull away. The Cullvisitor actually computes the correct transformation of each node and pushes objects into the the draw stage, which is executed after the Cullvisitor has visited all nodes. Therefore, the CullCallback is the latest point, we can influence a nodes transform before it is rendered. However the cullcallback is executed after the node transforms have already been pushed into the render stage.If we would therefore execute the cullcallback directly on the camera, we would not see any positional change. We must therefore set the cullcallback on a node above the camera (we named it cameragroup) and then access its child:</p>
<p>“`c++<br>
class CUpdateCameraCallback : public osg::NodeCallback<br>
{<br>
public:<br>
CUpdateCameraCallback() : NodeCallback(){}<br>
void operator()(osg::Node <em>node, osg::NodeVisitor </em>nv)<br>
{<br>
// only execute this callback if in the culling stage<br>
if (nv-&gt;getVisitorType() == osg::NodeVisitor::CULL_VISITOR)<br>
{<br>
// the camera is the only child of the camera group<br>
osg::Camera <em>camera = dynamic_cast&lt;osg::Camera </em>&gt;(node-&gt;asGroup()-&gt;getChild(0));<br>
// The cullvisitor holds information about the current (main) camera<br>
osgUtil::CullVisitor<em> cv = static_cast&lt;osgUtil::CullVisitor</em>&gt;(nv);</p>
<pre><code>        if (camera != NULL)
{
// copy over the transforms of the main camera
camera-&gt;setProjectionMatrix(cv-&gt;getCurrentCamera()-&gt;getProjectionMatrix() );
camera-&gt;setViewMatrix(cv-&gt;getCurrentCamera()-&gt;getViewMatrix());
// set the eye point in the shader
g_cameraEyeU-&gt;set(cv-&gt;getEyePoint());
}
}
this-&gt;traverse(node, nv);
}</code></pre>
<p>};</p>
<pre><code>
Now we show , how to set up the camera correctly:
```c++
cameraGroup = new osg::Group();
m_reflectionCamera = new osg::Camera();
reflectionTransform = new osg::MatrixTransform();
cameraGroup-&gt;addChild(m_reflectionCamera);
m_reflectionCamera-&gt;addChild(reflectionTransform);
m_reflectionCamera-&gt;setClearMask(GL_DEPTH_BUFFER_BIT | GL_COLOR_BUFFER_BIT);
// render the camera before the main camera
m_reflectionCamera-&gt;setRenderOrder(osg::Camera::PRE_RENDER);
// write into a frame buffer later used as texture
m_reflectionCamera-&gt;setRenderTargetImplementation(osg::Camera::FRAME_BUFFER_OBJECT);
// prevent near clipping
m_reflectionCamera-&gt;setComputeNearFarMode(osg::CullSettings::DO_NOT_COMPUTE_NEAR_FAR);
// calculate all transforms in world space
m_reflectionCamera-&gt;setReferenceFrame(osg::Transform::ABSOLUTE_RF);
// set the viewport to the size of the texture
m_reflectionCamera-&gt;setViewport(0, 0, texSize, texSize);
m_reflectionCamera-&gt;setClearDepth(1.0);
//Important: set our cull callback on the cameragroup, not the camera itself
m_cameraGroupCallback = new CUpdateCameraCallback();
cameraGroup-&gt;setCullCallback(m_cameraGroupCallback);</code></pre>
<p>Calculating the actual reflection does not need any extra adjustements for distributed rendering, but is shown here for reference:<br>
“`c++<br>
// add a clipping plane, to clip everything below z=0.0.<br>
//beware, that vec4(a,b,c,d) is a plane equation with a,b,c the plane normal and d the plane height<br>
m_reflectionClipPlane = new osg::ClipPlane(0, osg::Vec4d(0.0, 0.0, 1.0, 0.0));<br>
m_reflectionClipNode = new osg::ClipNode;<br>
m_reflectionClipNode-&gt;addClipPlane(m_reflectionClipPlane);<br>
reflectionTransform-&gt;addChild(m_reflectionClipNode);<br>
// mirror the scene along the z axis<br>
reflectionTransform-&gt;setMatrix(osg::Matrix::scale(1.0, 1.0, -1.0));</p>
<pre><code>// render the reflection camera into a texture
osg::ref_ptr&lt;osg::Texture2D&gt; texture = new osg::Texture2D();
texture-&gt;setTextureSize(texSize, texSize);
m_reflectionCamera-&gt;attach((osg::Camera::BufferComponent) osg::Camera::COLOR_BUFFER0, texture);
osg::StateSet *cameraState = m_reflectionCamera-&gt;getOrCreateStateSet();
cameraState-&gt;setMode(GL_CULL_FACE, osg::StateAttribute::OFF | osg::StateAttribute::OVERRIDE);
// Set reflection textures
osg::StateSet* floorStateSet = reflectingSurface-&gt;getOrCreateStateSet();
floorStateSet-&gt;setTextureAttributeAndModes(0, texture, osg::StateAttribute::ON);</code></pre>
<pre><code>The complete reflection code is found in source/view/reflection.cpp and shaders/grid.(vert|frag)
## Distributed rendering with omegalib+osg+equalizer
When programming an application in omegalib, the underlying displaysystem (equalizer) is mostly opaque to the programmer. It is however important to understand what is going on, when programming for a distributed, parallel rendering environment such as the Data Arena. 
##### What is parallel rendering ?
Quoting the introduction chapter of the Equalizer programming guide:
(insert figure 1 of equalizer programming guide)
Figure ? illustrates the basic principle of any parallel rendering application. The  typical OpenGL application, for example using GLUT, has an event loop which redraws the scene, updates application data based on received events, and eventually renders a new frame.
A parallel rendering application uses the same basic execution model, extending it by separating the rendering code from the main event loop. The rendering code is then executed in parallel on different resources, depending on the configuration chosen at runtime.
##### How does parallel rendering work in omegalib ?
(insert diagramOmegaFrame.png)
Rendering a frame with omegalib 
The EqualizerDisplaySystem in omegalib runs the mainloop and calls the Configimpl startFrame method. ConfigImpl is a implementation of the Config class methods in Equalizer. For an in-depth discussion of the various Equalizer concepts, check out the Equalizer Programming Guide, it is recommended to read the Introduction chapter and the "Equalizer Parallel Rendering Framework" chapter. 
The master, which drives the slaves rendering, first shares all Events to all nodes, each node is then reponsible for handling these Events. When handling events, commonly things such as calculating the new camera position are performed. Then other shared data is synced, for example a user could sync the position of an object across the nodes. Next the update call is performed on the master, which calls the update method on all registered modules. The update method internally calculates the correct offset of each screen camera, therefore the camera position should not be changed after the update traversal anymore. The update callback is also the place for the user to do any larger computations, such as running a physics simulation step. The startFrame(version) method tells all slave nodes to update themselves. It carries the frame version to sync all nodes to render the same frame. After all updates have been performed all nodes render the frame, which translates to calls to the osgModule, which executes culling and drawing traversals. Finally all nodes are synced on the end of the frame again.
Of course, this process has some intrecate issues that can arise when building complex applications. Often looking at the source code of omegalib, without having to extensively debug, can solve the issue as the code is fairly well commented.
## Data sharing and dynamic geometry
Any moving objects, which are synchronized over multiple screens should use the shared data commit/update pattern.
Equalizer handles distribution of datastreams to clients. Data can be added/extracted from the stream by calling
```c++
// only run on master
void commitSharedData(omega::SharedOStream&amp; out)
{
out &lt;&lt; myPosition;
}
// only run on slaves!
void updateSharedData(omega::SharedIStream&amp; in)
{
in &gt;&gt; myPosition;
}</code></pre>
<p>on a omegamodule class. We implemented this for all the relevant game classes using a listener pattern:<br>
An interface is declared as<br>
“`c++<br>
class SharedDataListener {<br>
public:<br>
virtual void commitSharedData(omega::SharedOStream&amp; out) = 0;<br>
virtual void updateSharedData(omega::SharedIStream&amp; in) = 0;<br>
};</p>
<pre><code>and all classes which want to commit data to the stream inherit and implement this interface.
Then register the listening classes in you omega module and iteratively dispatch them. Note that the input must the same order as the output.
An example of synchronizing a dynamic gemeotry is the fence, which trails the bike in the Troen game.
First we create a Geometry with a vertex array and quad strip primitive set:
```c++
void FenceView::initializeFence()
{
m_coordinates = new osg::Vec3Array();
m_coordinates-&gt;setDataVariance(osg::Object::DYNAMIC);
m_geometry = new osg::Geometry();
m_geometry-&gt;setVertexArray(m_coordinates);
// use VBOs, not display lists. important for dynamic updates
m_geometry-&gt;setUseDisplayList(false);
m_drawArrays = new osg::DrawArrays(osg::PrimitiveSet::QUAD_STRIP, 0, 0);
m_geometry-&gt;addPrimitiveSet(m_drawArrays);
}</code></pre>
<p>In our update method, we add a new fence part, when the bike has moved a certain distance. When porting osg applications to omegalib, always make sure that all modified vertex arrays and geometry is dirtied, as else there will be crashes even if it runs fine under pure osg.<br>
“`c++<br>
void FenceView::addFencePart(osg::Vec3 currentPosition)<br>
// game fence part<br>
m_coordinates-&gt;push_back(currentPosition);<br>
m_coordinates-&gt;push_back(currentPosition + osg::Vec3(0,0,10));<br>
// trigger new boundary calculation<br>
m_geometry-&gt;dirtyBound();<br>
// very important to dirty vertex and attributes, as otherwise this will segfault in omegalib<br>
m_coordinates-&gt;dirty();<br>
// update the size of the draw array<br>
m_drawArrays-&gt;setCount(m_coordinates-&gt;size());<br>
// if its the master, cache the position to use in the commit data method<br>
if (omega::SystemManager::instance()-&gt;isMaster())<br>
{<br>
m_currentPositionCached = currentPosition;<br>
m_fenceUpdated = true;<br>
}</p>
<pre><code>
We call the *addFencePart* method in our update method, but only on the master. On the client, the method is called, when it receives new shared data:
```c++
void FenceView::commitSharedData(omega::SharedOStream&amp; out)
{
out &lt;&lt; m_fenceUpdated &lt;&lt; m_currentPositionCached;
// clear per frame states
m_fenceUpdated = false;
}
void FenceView::updateSharedData(omega::SharedIStream&amp; in)
{
in &gt;&gt; m_fenceUpdated &gt;&gt;  m_currentPositionCached;
if (m_fenceUpdated)
addFencePart(m_currentPositionCached);
}</code></pre>
<p>It is usually not necessary to sync the physics state, because the commit/update method is called every frame and the datalink in the Data Arena has a low latency. In Troen, we only synchronize the view transforms and do not execute the physics simulation on the child nodes at all. By doing this, we ensure that all nodes are in a consistent state and we do not have to worry about diverging physics states.</p>
<p>There can be situations however, where syncing the individual object transforms is not possible in a scalable manner, for example if a large particle system should be synced. In this case, the parameters of the particle system have to be synced and the simulation simultaneausly ran, setting random seeds uniformly.</p>
&nbsp;&nbsp;&nbsp;&nbsp;
<span class="sow-icon-fontawesome" data-sow-icon="" style="font-size: 24px; color: #3d3d3d"></span>			
<p class="sow-more-text">
<a href="/wordpress/tutorials/load-box/">						Previous Tutorial						</a>					</p>
<span class="sow-icon-fontawesome" data-sow-icon="" style="font-size: 24px; color: #3d3d3d"></span>			
<p class="sow-more-text">
<a href="/wordpress/tutorials/building-the-scenegraph/">						Next Tutorial						</a>					</p>